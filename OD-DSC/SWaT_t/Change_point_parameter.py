import numpy as np
import pandas as pd
import json




parameters = {
        #网络层结构
        'n_hidden_enc_1':[45, 45,45,45,45, 45,45,45,45,45, 45,45,45,45,45, 45,45,45,45,45,  45,45,45,45,45,  45,45,45,45,45,  45,45,45,45,45, 45,45,45,45,45,   45,45,45,45,45,  45,45],
        'n_hidden_enc_2':[33,33, 33,33,33, 33,33, 33,33,33, 33,33, 33,33,33, 33,33, 33,33,33,  33,33, 33,33,33,  33,33,33,33,33,  33,33,33,33,33, 33,33,33,33,33,   33,33,33,33,33,  33,33],
        'n_hidden_dec_2':[33,33,33,33,33,  33,33, 33,33,33, 33,33, 33,33,33, 33,33, 33,33,33,  33,33, 33,33,33,  33,33,33,33,33,  33,33,33,33,33, 33,33,33,33,33,   33,33,33,33,33,   33,33],
        'n_hidden_dec_1':[45,45,45,45,45,  45,45,45,45,45, 45,45,45,45,45, 45,45,45,45,45,  45,45,45,45,45,  45,45,45,45,45,  45,45,45,45,45, 45,45,45,45,45,   45,45,45,45,45,  45,45],
        #训练DSC损失的参数
        'alpha_dsc_a1':[1,1,1,1,1,      1,1,1,1,1, 1,1,1,1,1, 1,1,1,1,1,  1,1,1,1,1,   1,1,1,1,1,  1,1,1,1,1, 1,1,1,1,1,   1,1,1,1,1,  1,1],
        'alpha_dsc_a2':[10,10,10,10,10, 10,10,10,10,10, 10,10,10,10,10, 10,10,10,10,10,   10,10,10,10,10,    10,10,10,10,10, 10,10,10,10,10, 10,10,10,10,10,   10,10,10,10,10,  10,10],
        #确定相似度矩阵的参数：
        'ro':   [0.45,0.45,0.45,0.45,0.45,      0.45,0.45,0.45,0.467,0.515,       0.515,0.318,0.318,0.318,0.32,        0.32,0.32,0.32,0.39,0.39,   0.39,0.3,0.3,0.3,0.384,   0.384,0.384,0.3,0.3,0.3,  0.3,0.42,0.42,0.42,0.42,  0.59,0.59,0.59,0.59,0.59,   0.9,0.9,0.9,0.9,0.9,  0.9,0.9],
        'alpha':[0.9,0.9,0.9,0.9,0.5,     0.5, 0.5, 0.5, 0.95, 0.95,  0.95,0.95,0.95,0.95,0.45,   0.45,0.45,0.45,0.9,0.9,   0.9,0.9,0.9,0.9,0.9,
                 0.95,0.95,0.95,0.95,0.95,  0.95,0.95,0.95,0.95,0.95,  0.48,0.48,0.48,0.48,0.48,    0.9,0.9,0.9,0.9,0.9,   0.9,0.9],
        'd':[50,50,50,50,50,                     50,50,50,50,50,         50,50,50,50,50, 50,50,50,50,50,  50,50,50,50,50,    50,50,50,50,50,  50,50,50,50,50,  50,50,50,50,50,   50,50,50,50,50,  50,50],
        #聚簇的参数
        'Similarity_threshold':   [0.7,0.7,0.7,0.7,0.7,           0.7,0.7,0.7,0.7,0.7,       0.7,0.7,0.7,0.7,0.7,      0.7,0.7,0.7,0.7,0.7,  0.7,0.7,0.7,0.7,0.7,
                                   0.7,0.7,0.7,0.7,0.7,  0.7,0.7,0.7,0.7,0.7,   0.7,0.7,0.7,0.7,0.7,   0.7,0.7,0.7,0.7,0.7,   0.7,0.7],  # 相似度阈值
        'Large_cluster_threshold':[0.85,0.85,0.85,0.85,0.85,      0.85,0.85,0.85,0.85,0.85,   0.85,0.85,0.85,0.85,0.85,      0.85,0.85,0.85,0.85,0.8, 0.85,0.85,0.85,0.85,0.855,
                                   0.85,0.85,0.85,0.85,0.85,  0.85,0.85,0.85,0.85,0.85,   0.85,0.85,0.85,0.85,0.85,   0.85,0.85,0.85,0.85,0.85,  0.85,0.85],    #大簇阈值
        'Microcluster_threshold':[10,10,10,10,10,   10,10,10,10,10,   10,10,10,10,10,      10,10,10,10,10,     10,10,10,10,10,    10,10,10,10,10,  10,10,10,10,10,  10,10,10,10,10,   10,10,10,10,10,  10,10],
        #R_threshold:细筛部分用到的RMSE阈值
        'R_threshold':[0.33,0.33,0.33,0.33,0.33,    0.4,0.4,0.4,0.5,0.5,   0.5,0.5,0.5,0.5,0.4,    0.4,0.4,0.4,0.34,0.34,  0.34,0.4,0.4,0.4,0.32,    0.32,0.32,0.37,0.37,0.37,  0.37,0.3,0.3,0.3,0.3,   0.35,0.35,0.35,0.35,0.35,   0.33,0.33,0.33,0.33,0.33,   0.33,0.33],
        #Gco_Q: Great_clusters_outliers_quantity
        'Gco_Q':[0,0,0,0,0, 0,0,0,0,0, 0,0,0,0,0, 0,0,0,0,0,  0,0,0,0,0,   0,0,0,0,0,  0,0,0,0,0,   0,0,0,0,0,   0,0,0,0,0,  0,0],
        'C_point_index':[1,1,1,1,5, 5,5,5,9,10, 10,12,12,12,15, 15,15,15,19,19,  19,22,22,22,25,    25,25,28,28,28, 28,32,32,32,32,   36,36,36,36,36,   41,42,43,44,45,   46,47]
        }
# pd.DataFrame(parameters)
# print(parameters['Large_cluster_threshold'][5])


# 转换为DataFrame
df = pd.DataFrame(parameters)

# 保存为json文件
df.to_json('./parameters_dict.json', orient='records', lines=True)

df.head()

# 读取 JSON 文件
df = pd.read_json('./parameters_dict.json', orient='records', lines=True)

# 将 DataFrame 转换为字典列表
data = df.to_dict(orient='records')

# 格式化并保存为易读的 JSON 文件
with open('./parameters_formatted.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)

# 打印格式化后的 JSON
print(json.dumps(data, ensure_ascii=False, indent=4))